{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0acc9c",
   "metadata": {},
   "source": [
    "# Assistant de Recherche pour la Génération Automatique de README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8e2a72",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "\n",
    "### Objectif du projet :\n",
    "Ce projet vise à générer automatiquement un README à partir d’un projet Python (ou multi-langage) existant.\n",
    "\n",
    "Il simplifie la vie des développeurs et des équipes en :\n",
    "- Fournissant une documentation structurée, même pour du code peu commenté.\n",
    "- Évitant de devoir écrire manuellement le README pour chaque projet.\n",
    "- Permettant une mise à jour rapide de la documentation à chaque modification du code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba6face",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafeb17",
   "metadata": {},
   "source": [
    "### Paramétrage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5eefbf",
   "metadata": {},
   "source": [
    "1. Importation des bibliothèques nécessaires :\n",
    "   \n",
    "On commence par importer toutes les bibliothèques utiles pour le projet.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37af9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires pour le projet.\n",
    "\n",
    "import os            # Pour les opérations système (gestion des chemins, etc.)\n",
    "import re            # Pour les expressions régulières (utilisé pour le chunking)\n",
    "import json          # Pour la gestion des fichiers JSON (notamment les .ipynb)\n",
    "import numpy as np   # Pour les opérations numériques (essentiel pour les embeddings)\n",
    "from dotenv import load_dotenv # Pour charger la clé API depuis un fichier .env\n",
    "from mistralai import Mistral # SDK officiel pour interagir avec Mistral AI\n",
    "import faiss         # Bibliothèque d'indexation vectorielle (recherche d'embeddings)\n",
    "import time          # Pour la gestion des pauses (retry en cas d'erreur 429)\n",
    "import random        # Pour la gestion des pauses aléatoires (backoff jitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e234510",
   "metadata": {},
   "source": [
    "2. Récupération de la clé API pour l'appel à Miastral AI.\n",
    "\n",
    "Cette étape est cruciale pour sécuriser la clé API et permettre l’accès aux services Mistral AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76449ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe24625",
   "metadata": {},
   "source": [
    "3. Exclusion de fichiers/dossiers inutiles\n",
    "\n",
    "Le pipeline n’analyse que le code pertinent. On exclut donc :\n",
    "- Les environnements virtuels, caches, artefacts de build, fichiers binaires.\n",
    "- Les fichiers temporaires et images inutiles à l’analyse.\n",
    "\n",
    "Cela améliore les performances et réduit le nombre de chunks inutiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1562080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des dossiers à exclure (Python, Node.js, Java, etc.)\n",
    "excluded_dirs = {\n",
    "    # Python\n",
    "    \"venv\", \".venv\", \"__pycache__\", \"site-packages\", \"env\", \".env\",\n",
    "    # Node.js / JS\n",
    "    \"node_modules\", \"bower_components\", \".npm\", \".yarn\",\n",
    "    # Java / JVM\n",
    "    \"target\", \"build\", \".gradle\", \".mvn\", \"out\",\n",
    "    # C/C++ / Rust / Go / .NET\n",
    "    \"cmake-build-debug\", \"cmake-build-release\", \"bin\", \"obj\", \"pkg\", \"dist\",\n",
    "    \"Debug\", \"Release\",\n",
    "    # Divers IDE / SCM\n",
    "    \".git\", \".svn\", \".hg\", \".idea\", \".vscode\"\n",
    "}\n",
    "\n",
    "# Liste des fichiers à exclure (souvent générés automatiquement ou inutiles à l'analyse)\n",
    "excluded_files = {\n",
    "    # SCM / VCS\n",
    "    \".gitignore\", \".gitattributes\", \".gitmodules\",\n",
    "    \".hgignore\", \".svnignore\",\n",
    "\n",
    "    # Config / lockfiles\n",
    "    \"package-lock.json\", \"yarn.lock\", \"pnpm-lock.yaml\",\n",
    "    \"poetry.lock\", \"Pipfile.lock\",\n",
    "\n",
    "    # Build / cache\n",
    "    \"Thumbs.db\", \"Desktop.ini\",\n",
    "    \".DS_Store\",  # macOS\n",
    "    \"npm-debug.log\", \"yarn-error.log\",\n",
    "    \"Cargo.lock\", \"Gemfile.lock\",\n",
    "\n",
    "    # Environnements\n",
    "    \".env\", \".env.local\", \".env.production\", \".env.development\",\n",
    "\n",
    "    # Binaires / artefacts\n",
    "    \"*.pyc\", \"*.pyo\", \"*.pyd\",\n",
    "    \"*.class\", \"*.jar\", \"*.war\", \"*.ear\",\n",
    "    \"*.dll\", \"*.so\", \"*.dylib\",\n",
    "    \"*.exe\", \"*.out\", \"*.o\", \"*.obj\",\n",
    "    \"*.a\", \"*.lib\",\n",
    "\n",
    "    # Archives\n",
    "    \"*.zip\", \"*.tar\", \"*.gz\", \"*.bz2\", \"*.rar\",\n",
    "\n",
    "    # Divers\n",
    "    \"README.md\", \"LICENSE\", \"COPYING\", \"CHANGELOG\", \"TODO\", \"Makefile\",\n",
    "    \n",
    "    # Photos \n",
    "    \"*.png\", \"*.jpg\", \"*.jpeg\", \"*.gif\", \"*.bmp\", \"*.svg\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b244c8",
   "metadata": {},
   "source": [
    "## Fonctions principales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbec4cb",
   "metadata": {},
   "source": [
    "1. Affichage de l’arborescence (show_tree)\n",
    "\n",
    "Cette fonction affiche l’arborescence du projet jusqu’au second niveau seulement.\n",
    "\n",
    "Cela évite d’afficher des milliers de fichiers pour les gros projets. Et donc de se limiter au premier et second niveaux dans l'arborescence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f809a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_tree(root):\n",
    "    \"\"\"\n",
    "    Affiche :\n",
    "    - Tous les fichiers du premier niveau\n",
    "    - Tous les fichiers du second niveau\n",
    "    - Tous les sous-dossiers du second niveau indiqués avec '...'\n",
    "    - Ne descend pas au troisième niveau ou plus\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        # Filtrage des dossiers exclus\n",
    "        dirnames[:] = [d for d in dirnames if d not in excluded_dirs]\n",
    "        filenames[:] = [f for f in filenames if f not in excluded_files]\n",
    "\n",
    "        # Niveau dans l'arborescence\n",
    "        level = dirpath.replace(root, \"\").count(os.sep)\n",
    "        indent = \" \" * 4 * level\n",
    "\n",
    "        # Nom du dossier courant\n",
    "        lines.append(f\"{indent}{os.path.basename(dirpath)}/\")\n",
    "\n",
    "        if level == 0:\n",
    "            # Fichiers du root\n",
    "            for f in filenames:\n",
    "                lines.append(f\"{indent}    {f}\")\n",
    "\n",
    "            # Sous-dossiers niveau 1\n",
    "            for d in dirnames:\n",
    "                lines.append(f\"{indent}    {d}/\")\n",
    "\n",
    "        elif level == 1:\n",
    "            # Fichiers du second niveau\n",
    "            for f in filenames:\n",
    "                lines.append(f\"{indent}    {f}\")\n",
    "\n",
    "            # Sous-dossiers du second niveau → seulement \"...\"\n",
    "            for d in dirnames:\n",
    "                lines.append(f\"{indent}    {d}/ ...\")\n",
    "\n",
    "        else:\n",
    "            dirnames[:] = []  # empêche d'aller plus loin\n",
    "\n",
    "        # Empêche la descente au-delà du second niveau\n",
    "        if level >= 2:\n",
    "            dirnames[:] = []\n",
    "\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34440f6",
   "metadata": {},
   "source": [
    "2. Lecture du code (read_code)\n",
    "\n",
    "Cette fonction lit uniquement le code exploitable :\n",
    "- Pour les .ipynb, seules les cellules de type \"code\" sont conservées.\n",
    "- Pour les autres fichiers, tout le contenu est récupéré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888448b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code(file_path):\n",
    "    \"\"\"\n",
    "    Lit le contenu d'un fichier de code et renvoie uniquement le code exploitable.\n",
    "\n",
    "    - Pour les fichiers Jupyter Notebook (.ipynb) : \n",
    "      ne conserve que le contenu des cellules de type 'code', et les concatène en une seule chaîne de caractères.\n",
    "    - Pour les autres fichiers de code (.py, .js, .cpp, etc.) :\n",
    "      lit l'intégralité du fichier et retourne son contenu brut.\n",
    "\n",
    "    Paramètre :\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Chemin vers le fichier à lire.\n",
    "\n",
    "    Retour :\n",
    "    -------\n",
    "    str\n",
    "        Contenu du code du fichier, prêt à être utilisé pour le traitement ou\n",
    "        pour la génération de chunks dans un pipeline de documentation.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".ipynb\":\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = json.load(f)\n",
    "            content = []\n",
    "            for cell in nb.get(\"cells\", []):\n",
    "                if cell.get(\"cell_type\") == \"code\":\n",
    "                    content.append(\"\".join(cell.get(\"source\", [])))\n",
    "            return \"\\n\".join(content)\n",
    "\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00662dc",
   "metadata": {},
   "source": [
    "## Découpage du code en chunks + embedding\n",
    "\n",
    "1. Découpage du code en chunks\n",
    "\n",
    "Nous avons donc deux fonctions qui travaillent ensemble:\n",
    "- split_functions : découpe le code en fonctions ou blocs logiques.\n",
    "- split_long_chunk : si un chunk est trop long, on le découpe en morceaux plus petits.\n",
    "\n",
    "Cela permet d'assurer que chaque chunk respecte la limite maximale pour l’API d’embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc8f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_functions(code):\n",
    "    \"\"\"Découpe le code en fonctions/chunks.\"\"\"\n",
    "    pattern = r\"(def [\\w_]+\\s*\\(.*?\\):(?:\\n(?:\\s+.+))*)\"\n",
    "    chunks = re.findall(pattern, code, re.DOTALL)\n",
    "    return chunks if chunks else [code]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a10f52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taille max en caractères pour un chunk envoyé aux embeddings\n",
    "MAX_CHARS_PER_CHUNK = 5000\n",
    "\n",
    "def split_long_chunk(chunk, max_chars=MAX_CHARS_PER_CHUNK):\n",
    "    \"\"\"\n",
    "    Si un chunk est trop long, on le découpe en morceaux plus petits basés sur les lignes.\n",
    "    On essaye de garder des morceaux cohérents tout en respectant la limite de taille.\n",
    "    \"\"\"\n",
    "    if len(chunk) <= max_chars:\n",
    "        return [chunk]\n",
    "\n",
    "    lines = chunk.splitlines()\n",
    "    parts = []\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # +1 pour le saut de ligne\n",
    "        extra = len(line) + 1\n",
    "        # Si on dépasse la limite, on coupe ici\n",
    "        if current_len + extra > max_chars and current:\n",
    "            parts.append(\"\\n\".join(current))\n",
    "            current = [line]\n",
    "            current_len = extra\n",
    "        else:\n",
    "            current.append(line)\n",
    "            current_len += extra\n",
    "\n",
    "    if current:\n",
    "        parts.append(\"\\n\".join(current))\n",
    "\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3325f7",
   "metadata": {},
   "source": [
    "2. Création des embeddings\n",
    "\n",
    "Chaque chunk est transformé en vecteur numérique grâce au modèle codestral-embed.\n",
    "\n",
    "Cela permet d'avoir une bonne gestion des erreurs 429 avec backoff exponentiel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9afe115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(chunks, batch_size=16, max_retries=5):\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = client.embeddings.create(\n",
    "                    model=\"codestral-embed\",\n",
    "                    inputs=batch\n",
    "                )\n",
    "                for emb in resp.data:\n",
    "                    embeddings.append(np.array(emb.embedding, dtype=np.float32))\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e):\n",
    "                    wait = 2 ** attempt + random.random()\n",
    "                    print(f\"Erreur 429… Retry dans {wait:.2f}s\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3304a8c2",
   "metadata": {},
   "source": [
    "3. Parcours du projet (itération sur fichiers)\n",
    "\n",
    "Cette fonction récupère seulement les fichiers code utiles, en respectant les exclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196c031",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_project_files(folder_path, code_ext):\n",
    "    \"\"\"Itère uniquement sur les fichiers code utiles, en excluant dossiers et fichiers parasites.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        # On filtre les dossiers exclus\n",
    "        dirnames[:] = [d for d in dirnames if d not in excluded_dirs]\n",
    "\n",
    "        for f in filenames:\n",
    "            # Exclure les fichiers parasites\n",
    "            if f in excluded_files:\n",
    "                continue\n",
    "            # Exclure aussi par motif (ex: *.pyc, *.class, etc.)\n",
    "            for pattern in excluded_files:\n",
    "                if pattern.startswith(\"*.\") and f.endswith(pattern[1:]):\n",
    "                    break\n",
    "            else:\n",
    "                ext = os.path.splitext(f)[1].lower()\n",
    "                if ext in code_ext:\n",
    "                    yield os.path.join(dirpath, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621d0ef",
   "metadata": {},
   "source": [
    "## Pipeline de génération du README\n",
    "\n",
    "Nous avons décidé de suivre cette pipeline:\n",
    "1. Lecture et filtrage des fichiers code.\n",
    "2. Chunking et découpage.\n",
    "3. Création des embeddings.\n",
    "4. Indexation FAISS pour recherche par similarité.\n",
    "5. Construction du prompt RAG et génération du README via LLM.\n",
    "6. Sauvegarde du README dans le dossier du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6790f54",
   "metadata": {},
   "source": [
    "Le prompt RAG structure la génération pour garantir un README complet, clair et dans l’ordre :\n",
    "1. Titre du projet\n",
    "2. Présentation générale\n",
    "3. Arborescence\n",
    "4. Bibliothèques\n",
    "5. Résumé fichier par fichier\n",
    "6. Instructions pour lancer le projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49640cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_readme_RAG(folder_path, output_file):\n",
    "\n",
    "    # ---- 3.1 Lire fichiers code ----\n",
    "    code_ext = {\".py\", \".js\", \".ts\", \".cpp\", \".c\", \".java\", \".ipynb\", \".php\", \".html\"}\n",
    "    all_files = []\n",
    "    all_codes = []\n",
    "\n",
    "    for fp in iter_project_files(folder_path, code_ext):\n",
    "        code = read_code(fp)\n",
    "        if code.strip():\n",
    "            all_files.append(fp)\n",
    "            all_codes.append(code)\n",
    "\n",
    "    if not all_codes:\n",
    "        raise ValueError(\"Aucun fichier code trouvé dans ce dossier !\")\n",
    "\n",
    "  \n",
    "    # ---- 3.2 Chunking ----\n",
    "    chunks = []\n",
    "    chunk_paths = []\n",
    "\n",
    "    for file_path, code in zip(all_files, all_codes):\n",
    "        # Première étape : découper par fonctions / blocs\n",
    "        func_chunks = split_functions(code)\n",
    "\n",
    "        # Deuxième étape : si un chunk est trop long, on le re-découpe\n",
    "        for fc in func_chunks:\n",
    "            small_chunks = split_long_chunk(fc, max_chars=MAX_CHARS_PER_CHUNK)\n",
    "            for sc in small_chunks:\n",
    "                chunks.append(sc)\n",
    "                chunk_paths.append(file_path)\n",
    "\n",
    "    print(f\"Total chunks : {len(chunks)}\")\n",
    "\n",
    "\n",
    "    # ---- 3.3 Embeddings ----\n",
    "    embeddings = create_embeddings(chunks, batch_size=16)\n",
    "    dim = len(embeddings[0])\n",
    "\n",
    "    # ---- 3.4 Indexation FAISS ----\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "\n",
    "    # ---- 3.5 Arborescence ----\n",
    "    tree = show_tree(folder_path)\n",
    "\n",
    "    # ---- 3.6 Construire le prompt RAG final ----\n",
    "    prompt = f\"\"\"\n",
    "Tu es un expert en analyse de code. \n",
    "Voici une liste de chunks extraits du projet.\n",
    "\n",
    "Ton rôle :\n",
    "- Reconstituer le sens du projet\n",
    "- Faire un README.md professionnel et intuitif\n",
    "\n",
    "Tu dois au maximum respecter exactement la structure suivante,\n",
    "avec ces titres dans cet ordre, même si tu n'as pas toutes les informations :\n",
    "1. # Titre du projet\n",
    "2. # Présentation générale et fonctionnement\n",
    "3. # Arborescence du projet\n",
    "4. # Bibliothèques nécessaires pour le projet\n",
    "5. # Résumé fichier par fichier\n",
    "6. # Comment lancer le projet\n",
    "\n",
    "Si tu manques d'informations pour une section, écris clairement :\n",
    "\"Informations à compléter\" plutôt que de supprimer la section.\n",
    "\n",
    "Voici l'arborescence du dossier :\n",
    "-----------------\n",
    "{tree}\n",
    "-----------------\n",
    "\n",
    "Voici un échantillon de chunks utiles (non ordonnés) :\n",
    "-----------------\n",
    "{chunks[:200]}\n",
    "-----------------\n",
    "\n",
    "\n",
    "Pour 2. # Présentation générale et fonctionnement en 20-30 lignes maximum\n",
    "Pour 3. # Arborescence du projet, si elle est trop longue, réduis-la en ne gardant que les dossiers et fichiers importants.\n",
    "Pour 5. # Résumé fichier par fichier, classe les par catégories de languages si possible, et pour chaque fichier, indique en 2-3 lignes son rôle dans le projet.\n",
    "pOUR 6. # Comment lancer le projet, indique les étapes précises pour un utilisateur lambda.\n",
    "Conclus le README par les avertissements sur le projet, et les limitations connues, en 5-10 lignes maximum.\n",
    "\n",
    "IMPORTANT : \n",
    "- Ne mets **aucun bloc de code Markdown** autour du README.\n",
    "- Ne commence PAS par ```markdown, ```md ou tout autre fence.\n",
    "\n",
    "Génère maintenant un README Markdown complet et propre, en respectant EXACTEMENT les titres et l'ordre des sections listées plus haut.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.complete(\n",
    "        model=\"codestral-2508\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=5000\n",
    "    )\n",
    "\n",
    "    readme_text = response.choices[0].message.content\n",
    "\n",
    "    # ---- 3.7 Sauvegarde ----\n",
    "    # Si README.md existe, on crée README2.md\n",
    "    if os.path.exists(output_file):\n",
    "        base = os.path.dirname(output_file)\n",
    "        output_file = os.path.join(base, \"README2.md\")\n",
    "        print(\"README.md existant → génération dans README2.md\")\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme_text)\n",
    "\n",
    "    print(\"\\n README généré :\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748f04bc",
   "metadata": {},
   "source": [
    "## Création du README de l'utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c23760",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = input(\"Dossier à analyser : \").strip()\n",
    "output = os.path.join(folder, \"README.md\")\n",
    "\n",
    "generate_readme_RAG(folder, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc7eac",
   "metadata": {},
   "source": [
    "### Limites liées à la Parallélisation\n",
    "\n",
    "Certaines étapes (chunking, embeddings) pourraient être parallélisées.\n",
    "\n",
    "Toutefois, indexation FAISS et génération finale doivent rester séquentielles.\n",
    "\n",
    "Paralléliser peut même augmenter le coût mémoire et la communication entre processus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4feb03e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce projet avait pour objectif de générer automatiquement un README à partir d’un projet Python en utilisant une architecture RAG (Retrieval-Augmented Generation). L’intégration d’un parsing du code, d’embeddings vectoriels et d’un LLM a permis de produire une documentation structurée et cohérente, même en l’absence de commentaires dans le code source.\n",
    "\n",
    "Le système proposé se distingue par :\n",
    "- un chunking optimisé, adapté aux contraintes d’API ;\n",
    "- une exclusion intelligente des fichiers inutiles ;\n",
    "- un prompt RAG structuré, garantissant la qualité de la documentation générée.\n",
    "\n",
    "Les résultats sont encourageants, mais certaines limites persistent, notamment la scalabilité, la fenêtre contextuelle des modèles et la mémoire nécessaire à l’indexation, auxquelles s’ajoutent des bénéfices limités de la parallélisation dans une architecture locale. Pour dépasser ces contraintes, l’utilisation d’une indexation vectorielle cloud et de méthodes hiérarchiques de summarization constitue une perspective pertinente.\n",
    "Ainsi, ce travail confirme l’intérêt du RAG pour automatiser la documentation logicielle et ouvre la voie à des solutions plus robustes et adaptées à des projets de grande échelle.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
