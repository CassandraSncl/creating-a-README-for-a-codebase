{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdb67b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks : 99\n",
      "Erreur 429‚Ä¶ Retry dans 1.30s\n",
      "\n",
      " README g√©n√©r√© : D:\\33611\\Documents\\MASTER\\M2\\Open_data\\projet\\TourismEco\\README.md\n"
     ]
    }
   ],
   "source": [
    "# ================================================\n",
    "# IMPORTS\n",
    "# ================================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import faiss\n",
    "import time\n",
    "import random\n",
    "\n",
    "# ================================================\n",
    "# 0. Charger cl√© API\n",
    "# ================================================\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=api_key)\n",
    "\n",
    "# ================================================\n",
    "# 1. Fonctions utilitaires\n",
    "# ================================================\n",
    "def show_tree(root):\n",
    "    \"\"\"\n",
    "    Affiche :\n",
    "    - Tous les fichiers du premier niveau\n",
    "    - Tous les fichiers du second niveau\n",
    "    - Tous les sous-dossiers du second niveau indiqu√©s avec '...'\n",
    "    - Ne descend pas au troisi√®me niveau ou plus\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        # Filtrage des dossiers exclus\n",
    "        dirnames[:] = [d for d in dirnames if d not in excluded_dirs]\n",
    "        filenames[:] = [f for f in filenames if f not in excluded_files]\n",
    "\n",
    "        # Niveau dans l'arborescence\n",
    "        level = dirpath.replace(root, \"\").count(os.sep)\n",
    "        indent = \" \" * 4 * level\n",
    "\n",
    "        # Nom du dossier courant\n",
    "        lines.append(f\"{indent}{os.path.basename(dirpath)}/\")\n",
    "\n",
    "        if level == 0:\n",
    "            # Fichiers du root\n",
    "            for f in filenames:\n",
    "                lines.append(f\"{indent}    {f}\")\n",
    "\n",
    "            # Sous-dossiers niveau 1\n",
    "            for d in dirnames:\n",
    "                lines.append(f\"{indent}    {d}/\")\n",
    "\n",
    "        elif level == 1:\n",
    "            # Fichiers du second niveau\n",
    "            for f in filenames:\n",
    "                lines.append(f\"{indent}    {f}\")\n",
    "\n",
    "            # Sous-dossiers du second niveau ‚Üí seulement \"...\"\n",
    "            for d in dirnames:\n",
    "                lines.append(f\"{indent}    {d}/ ...\")\n",
    "\n",
    "        else:\n",
    "            dirnames[:] = []  # emp√™che d'aller plus loin\n",
    "\n",
    "        # Emp√™che la descente au-del√† du second niveau\n",
    "        if level >= 2:\n",
    "            dirnames[:] = []\n",
    "\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "\n",
    "def read_code(file_path):\n",
    "    \"\"\"Lit .py ou .ipynb et renvoie le code.\"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "    if ext == \".ipynb\":\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            nb = json.load(f)\n",
    "            content = []\n",
    "            for cell in nb.get(\"cells\", []):\n",
    "                if cell.get(\"cell_type\") == \"code\":\n",
    "                    content.append(\"\".join(cell.get(\"source\", [])))\n",
    "            return \"\\n\".join(content)\n",
    "\n",
    "    else:\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read()\n",
    "\n",
    "\n",
    "def split_functions(code):\n",
    "    \"\"\"D√©coupe le code en fonctions/chunks.\"\"\"\n",
    "    pattern = r\"(def [\\w_]+\\s*\\(.*?\\):(?:\\n(?:\\s+.+))*)\"\n",
    "    chunks = re.findall(pattern, code, re.DOTALL)\n",
    "    return chunks if chunks else [code]\n",
    "\n",
    "\n",
    "def gitignore(dossier_path):\n",
    "    \"\"\"Extrait les fichiers ignor√©s par .gitignore.\"\"\"\n",
    "    gitignore_path = os.path.join(dossier_path, \".gitignore\")\n",
    "    if not os.path.exists(gitignore_path):\n",
    "        return \"Aucun fichier .gitignore trouv√©.\"\n",
    "    ignored_files = []\n",
    "    with open(gitignore_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        ignored_files = [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n",
    "    return \"Fichiers ignor√©s par .gitignore :\\n\" + \"\\n\".join(ignored_files)\n",
    "\n",
    "\n",
    "def extract_imports(code):\n",
    "    \"\"\"Extrait toutes les biblioth√®ques import√©es.\"\"\"\n",
    "    imports = set()\n",
    "    for line in code.splitlines():\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"import \"):\n",
    "            imports.add(line.replace(\"import \", \"\").split()[0])\n",
    "        elif line.startswith(\"from \"):\n",
    "            imports.add(line.split()[1])\n",
    "    return imports\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 2. Embeddings + gestion des erreurs\n",
    "# ================================================\n",
    "def create_embeddings(chunks, batch_size=16, max_retries=5):\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = client.embeddings.create(\n",
    "                    model=\"codestral-embed\",\n",
    "                    inputs=batch\n",
    "                )\n",
    "                for emb in resp.data:\n",
    "                    embeddings.append(np.array(emb.embedding, dtype=np.float32))\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                if \"429\" in str(e):\n",
    "                    wait = 2 ** attempt + random.random()\n",
    "                    print(f\"Erreur 429‚Ä¶ Retry dans {wait:.2f}s\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 3. Pipe RAG : indexation + g√©n√©ration README\n",
    "# ================================================\n",
    "\n",
    "# üîπ Liste des dossiers √† exclure (Python, Node.js, Java, etc.)\n",
    "excluded_dirs = {\n",
    "    # Python\n",
    "    \"venv\", \".venv\", \"__pycache__\", \"site-packages\", \"env\", \".env\",\n",
    "    # Node.js / JS\n",
    "    \"node_modules\", \"bower_components\", \".npm\", \".yarn\",\n",
    "    # Java / JVM\n",
    "    \"target\", \"build\", \".gradle\", \".mvn\", \"out\",\n",
    "    # C/C++ / Rust / Go / .NET\n",
    "    \"cmake-build-debug\", \"cmake-build-release\", \"bin\", \"obj\", \"pkg\", \"dist\",\n",
    "    \"Debug\", \"Release\",\n",
    "    # Divers IDE / SCM\n",
    "    \".git\", \".svn\", \".hg\", \".idea\", \".vscode\"\n",
    "}\n",
    "\n",
    "# üîπ Liste des fichiers √† exclure (souvent g√©n√©r√©s automatiquement ou inutiles √† l'analyse)\n",
    "excluded_files = {\n",
    "    # SCM / VCS\n",
    "    \".gitignore\", \".gitattributes\", \".gitmodules\",\n",
    "    \".hgignore\", \".svnignore\",\n",
    "\n",
    "    # Config / lockfiles\n",
    "    \"package-lock.json\", \"yarn.lock\", \"pnpm-lock.yaml\",\n",
    "    \"poetry.lock\", \"Pipfile.lock\",\n",
    "\n",
    "    # Build / cache\n",
    "    \"Thumbs.db\", \"Desktop.ini\",\n",
    "    \".DS_Store\",  # macOS\n",
    "    \"npm-debug.log\", \"yarn-error.log\",\n",
    "    \"Cargo.lock\", \"Gemfile.lock\",\n",
    "\n",
    "    # Environnements\n",
    "    \".env\", \".env.local\", \".env.production\", \".env.development\",\n",
    "\n",
    "    # Binaires / artefacts\n",
    "    \"*.pyc\", \"*.pyo\", \"*.pyd\",\n",
    "    \"*.class\", \"*.jar\", \"*.war\", \"*.ear\",\n",
    "    \"*.dll\", \"*.so\", \"*.dylib\",\n",
    "    \"*.exe\", \"*.out\", \"*.o\", \"*.obj\",\n",
    "    \"*.a\", \"*.lib\",\n",
    "\n",
    "    # Archives\n",
    "    \"*.zip\", \"*.tar\", \"*.gz\", \"*.bz2\", \"*.rar\",\n",
    "\n",
    "    # Divers\n",
    "    \"README.md\", \"LICENSE\", \"COPYING\", \"CHANGELOG\", \"TODO\", \"Makefile\",\n",
    "    \n",
    "    # Photos \n",
    "    \"*.png\", \"*.jpg\", \"*.jpeg\", \"*.gif\", \"*.bmp\", \"*.svg\"\n",
    "}\n",
    "\n",
    "\n",
    "def iter_project_files(folder_path, code_ext):\n",
    "    \"\"\"It√®re uniquement sur les fichiers code utiles, en excluant dossiers et fichiers parasites.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(folder_path):\n",
    "        # On filtre les dossiers exclus\n",
    "        dirnames[:] = [d for d in dirnames if d not in excluded_dirs]\n",
    "\n",
    "        for f in filenames:\n",
    "            # Exclure les fichiers parasites\n",
    "            if f in excluded_files:\n",
    "                continue\n",
    "            # Exclure aussi par motif (ex: *.pyc, *.class, etc.)\n",
    "            for pattern in excluded_files:\n",
    "                if pattern.startswith(\"*.\") and f.endswith(pattern[1:]):\n",
    "                    break\n",
    "            else:\n",
    "                ext = os.path.splitext(f)[1].lower()\n",
    "                if ext in code_ext:\n",
    "                    yield os.path.join(dirpath, f)\n",
    "\n",
    "# Taille max en caract√®res pour un chunk envoy√© aux embeddings\n",
    "MAX_CHARS_PER_CHUNK = 6000\n",
    "\n",
    "def split_long_chunk(chunk, max_chars=MAX_CHARS_PER_CHUNK):\n",
    "    \"\"\"\n",
    "    Si un chunk est trop long, on le d√©coupe en morceaux plus petits bas√©s sur les lignes.\n",
    "    On essaye de garder des morceaux coh√©rents tout en respectant la limite de taille.\n",
    "    \"\"\"\n",
    "    if len(chunk) <= max_chars:\n",
    "        return [chunk]\n",
    "\n",
    "    lines = chunk.splitlines()\n",
    "    parts = []\n",
    "    current = []\n",
    "    current_len = 0\n",
    "\n",
    "    for line in lines:\n",
    "        # +1 pour le saut de ligne\n",
    "        extra = len(line) + 1\n",
    "        # Si on d√©passe la limite, on coupe ici\n",
    "        if current_len + extra > max_chars and current:\n",
    "            parts.append(\"\\n\".join(current))\n",
    "            current = [line]\n",
    "            current_len = extra\n",
    "        else:\n",
    "            current.append(line)\n",
    "            current_len += extra\n",
    "\n",
    "    if current:\n",
    "        parts.append(\"\\n\".join(current))\n",
    "\n",
    "    return parts\n",
    "\n",
    "\n",
    "def generate_readme_RAG(folder_path, output_file):\n",
    "\n",
    "    # ---- 3.1 Lire fichiers code ----\n",
    "    code_ext = {\".py\", \".js\", \".ts\", \".cpp\", \".c\", \".java\", \".ipynb\", \".php\", \".html\"}\n",
    "    all_files = []\n",
    "    all_codes = []\n",
    "\n",
    "    for fp in iter_project_files(folder_path, code_ext):\n",
    "        code = read_code(fp)\n",
    "        if code.strip():\n",
    "            all_files.append(fp)\n",
    "            all_codes.append(code)\n",
    "\n",
    "    if not all_codes:\n",
    "        raise ValueError(\"Aucun fichier code trouv√© dans ce dossier !\")\n",
    "\n",
    "  \n",
    "    # ---- 3.2 Chunking ----\n",
    "    chunks = []\n",
    "    chunk_paths = []\n",
    "\n",
    "    for file_path, code in zip(all_files, all_codes):\n",
    "        # Premi√®re √©tape : d√©couper par fonctions / blocs\n",
    "        func_chunks = split_functions(code)\n",
    "\n",
    "        # Deuxi√®me √©tape : si un chunk est trop long, on le re-d√©coupe\n",
    "        for fc in func_chunks:\n",
    "            small_chunks = split_long_chunk(fc, max_chars=MAX_CHARS_PER_CHUNK)\n",
    "            for sc in small_chunks:\n",
    "                chunks.append(sc)\n",
    "                chunk_paths.append(file_path)\n",
    "\n",
    "    print(f\"Total chunks : {len(chunks)}\")\n",
    "\n",
    "\n",
    "    # ---- 3.3 Embeddings ----\n",
    "    embeddings = create_embeddings(chunks, batch_size=16)\n",
    "    dim = len(embeddings[0])\n",
    "\n",
    "    # ---- 3.4 Indexation FAISS ----\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "\n",
    "    # ---- 3.5 Arborescence ----\n",
    "    tree = show_tree(folder_path)\n",
    "\n",
    "    # ---- 3.6 Construire le prompt RAG final ----\n",
    "    prompt = f\"\"\"\n",
    "Tu es un expert en analyse de code. \n",
    "Voici une liste de chunks extraits du projet.\n",
    "\n",
    "Ton r√¥le :\n",
    "- Reconstituer le sens du projet\n",
    "- Faire un README.md professionnel et intuitif\n",
    "\n",
    "Tu dois au maximum respecter exactement la structure suivante,\n",
    "avec ces titres dans cet ordre, m√™me si tu n'as pas toutes les informations :\n",
    "1. # Titre du projet\n",
    "2. # Pr√©sentation g√©n√©rale et fonctionnement\n",
    "3. # Arborescence du projet\n",
    "4. # Biblioth√®ques n√©cessaires pour le projet\n",
    "5. # R√©sum√© fichier par fichier\n",
    "6. # Comment lancer le projet facilement\n",
    "\n",
    "Si tu manques d'informations pour une section, √©cris clairement :\n",
    "\"Informations √† compl√©ter\" plut√¥t que de supprimer la section.\n",
    "\n",
    "Voici l'arborescence du dossier :\n",
    "-----------------\n",
    "{tree}\n",
    "-----------------\n",
    "\n",
    "Voici un √©chantillon de chunks utiles (non ordonn√©s) :\n",
    "-----------------\n",
    "{chunks[:150]}\n",
    "-----------------\n",
    "\n",
    "G√©n√®re maintenant un README Markdown complet et propre, en respectant EXACTEMENT les titres et l'ordre des sections list√©es plus haut.\n",
    "Pour 2. # Pr√©sentation g√©n√©rale et fonctionnement en 20-30 lignes maximum\n",
    "Pour 3. # Arborescence du projet, si elle est trop longue, r√©duis-la en ne gardant que les dossiers et fichiers importants.\n",
    "Pour 5. # R√©sum√© fichier par fichier, classe les par cat√©gories de languages si possible, et pour chaque fichier, indique en 2-3 lignes son r√¥le dans le projet.\n",
    "Conclus le README par les avertissements sur le projet, et les limitations connues, en 5-10 lignes maximum.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    response = client.chat.complete(\n",
    "        model=\"codestral-2508\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=2000\n",
    "    )\n",
    "\n",
    "    readme_text = response.choices[0].message.content\n",
    "\n",
    "    # ---- 3.7 Sauvegarde ----\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(readme_text)\n",
    "\n",
    "    print(\"\\n README g√©n√©r√© :\", output_file)\n",
    "\n",
    "\n",
    "# ================================================\n",
    "# 4. DEMANDE UTILISATEUR\n",
    "# ================================================\n",
    "folder = input(\"Dossier √† analyser : \").strip()\n",
    "output = os.path.join(folder, \"README.md\")\n",
    "\n",
    "if os.path.exists(output):\n",
    "    os.remove(output)\n",
    "\n",
    "generate_readme_RAG(folder, output)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
