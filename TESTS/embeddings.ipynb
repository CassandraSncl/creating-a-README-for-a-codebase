{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5276e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dc30834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Charger la clé depuis le fichier .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3a00f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de chunks : 2\n",
      "Réponse du LLM :\n",
      " # Fonction du fichier `generate_transaction.py`\n",
      "\n",
      "Ce fichier Python a pour objectif de générer des fichiers CSV contenant des transactions bancaires de manière simulée, en imitant un flux continu de données.\n",
      "\n",
      "## Fonctionnement détaillé du code :\n",
      "\n",
      "1. **Importation des bibliothèques** :\n",
      "   - `pandas` pour manipuler les données\n",
      "   - `random` pour générer des nombres aléatoires\n",
      "   - `os` pour gérer les chemins de fichiers\n",
      "   - `time` pour gérer les temporisations et les horodatages\n",
      "\n",
      "2. **Chargement des données** :\n",
      "   - Le code lit un fichier CSV nommé `stream.csv` qui contient les transactions bancaires\n",
      "\n",
      "3. **Boucle infinie** :\n",
      "   - Le script entre dans une boucle infinie (`while True`) qui génère continuellement des fichiers de transactions\n",
      "\n",
      "4. **Génération des sous-ensembles de transactions** :\n",
      "   - À chaque itération, il sélectionne un nombre aléatoire de transactions (entre 1 et 150) à exporter\n",
      "   - Il utilise un index `i` pour parcourir le fichier source de manière circulaire (quand il atteint la fin, il repart du début)\n",
      "\n",
      "5. **Création des fichiers** :\n",
      "   - Chaque sous-ensemble est enregistré dans un nouveau fichier CSV\n",
      "   - Les fichiers sont nommés avec un format spécifique : `transactions_{nombre_de_transactions}_{timestamp}.csv`\n",
      "   - Les fichiers sont enregistrés dans un répertoire nommé `output`\n",
      "\n",
      "6. **Temporisation** :\n",
      "   - Le script attend 2 secondes entre chaque génération de fichier\n",
      "\n",
      "## Utilité globale :\n",
      "Ce script simule un système qui génère des fichiers de transactions bancaires de manière continue, comme un système de traitement de données en temps réel. Il pourrait être utilisé pour :\n",
      "- Tester des systèmes de traitement de transactions\n",
      "- Simuler un flux de données pour des applications de monitoring\n",
      "- Générer des données d'exemple pour des démonstrations\n",
      "\n",
      "Le code est conçu pour fonctionner indéfiniment, générant constamment de nouveaux fichiers de transactions avec des tailles variables.\n"
     ]
    }
   ],
   "source": [
    "# 1. Lire fichiers .py et .ipynb\n",
    "def read_code(folder, extensions={\".py\", \".ipynb\"}):\n",
    "    code_files = []\n",
    "    for dirpath, _, filenames in os.walk(folder):\n",
    "        for f in filenames:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            full_path = os.path.join(dirpath, f)\n",
    "            if ext in extensions:\n",
    "                if ext == \".ipynb\":\n",
    "                    with open(full_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        nb = json.load(file)\n",
    "                        for cell in nb.get(\"cells\", []):\n",
    "                            if cell.get(\"cell_type\") == \"code\":\n",
    "                                code_files.append(\"\".join(cell.get(\"source\", [])))\n",
    "                else:\n",
    "                    with open(full_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                        code_files.append(file.read())\n",
    "    return code_files\n",
    "\n",
    "# 2. Découper par fonction\n",
    "def split_functions(code):\n",
    "    pattern = r\"(def [\\w_]+\\s*\\(.*?\\):(?:\\n(?:\\s+.+))*)\"\n",
    "    funcs = re.findall(pattern, code, re.DOTALL)\n",
    "    return funcs if funcs else [code]\n",
    "\n",
    "# 3. Créer embeddings\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "def create_embeddings(chunks, batch_size=16, max_retries=5):\n",
    "    \"\"\"\n",
    "    Crée des embeddings pour une liste de textes (chunks) en batch\n",
    "    et gère les erreurs 429 avec retry exponentiel.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list of str): textes à encoder\n",
    "        batch_size (int): nombre de chunks à envoyer par requête\n",
    "        max_retries (int): nombre de tentatives en cas d'erreur 429\n",
    "    Returns:\n",
    "        embeddings (list of np.array): embeddings de chaque chunk\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = client.embeddings.create(\n",
    "                    model=\"codestral-embed\",\n",
    "                    inputs=batch\n",
    "                )\n",
    "                # Ajouter chaque embedding du batch\n",
    "                for emb in resp.data:\n",
    "                    embeddings.append(np.array(emb.embedding, dtype=np.float32))\n",
    "                break  # sortir de la boucle retry si OK\n",
    "            except Exception as e:\n",
    "                # Vérifie si c'est une erreur 429\n",
    "                if \"429\" in str(e):\n",
    "                    wait = 2 ** attempt + random.random()\n",
    "                    print(f\"Erreur 429, tentative {attempt+1}/{max_retries}. Attente {wait:.2f}s\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    raise e  # autre erreur → remonter\n",
    "    return embeddings\n",
    "\n",
    "# 4. Lire + chunker + embeddings\n",
    "folder = \"D:\\\\33611\\\\Documents\\\\MASTER\\\\M2\\\\BIG_DATA\\\\TP4\\\\data\"\n",
    "all_code = read_code(folder)\n",
    "all_chunks = []\n",
    "for code in all_code:\n",
    "    all_chunks.extend(split_functions(code))\n",
    "embeddings = create_embeddings(all_chunks,batch_size=8)\n",
    "print(f\"Nombre de chunks : {len(all_chunks)}\")\n",
    "\n",
    "# 5. Stocker dans FAISS\n",
    "dim = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# 6. Fonction pour poser une question au LLM avec RAG\n",
    "def ask_question(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Pose une question sur le code en utilisant RAG avec Mistral plus léger.\n",
    "    \"\"\"\n",
    "    # 1. Créer l'embedding de la question\n",
    "    query_emb = client.embeddings.create(\n",
    "        model=\"codestral-embed\",  # embeddings restent les mêmes\n",
    "        inputs=[query]\n",
    "    )\n",
    "    q_vec = np.array(query_emb.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # 2. Chercher les chunks les plus proches dans FAISS\n",
    "    D, I = index.search(q_vec, k=top_k)\n",
    "    context = \"\\n\\n\".join([all_chunks[i] for i in I[0]])\n",
    "\n",
    "    # 3. Préparer le prompt pour le LLM\n",
    "    prompt = (\n",
    "        \"Voici le code extrait :\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"Question : {query}\\n\"\n",
    "        \"Réponds de manière claire et précise, explique le fonctionnement du code si nécessaire.\"\n",
    "    )\n",
    "\n",
    "    # 4. Appeler le LLM Mistral plus léger\n",
    "    response = client.chat.complete(\n",
    "        model=\"codestral-2508\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=600\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 7. Exemple\n",
    "question = \"A quoi sert le fichier generate_transaction.py ?\"\n",
    "answer = ask_question(question)\n",
    "print(\"Réponse du LLM :\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83cf59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object='list' data=[BaseModelCard(id='mistral-medium-2505', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-medium-2505', description='Our frontier-class multimodal model released May 2025.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-large-latest', description='Official mistral-large-latest Mistral AI model', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium-2508', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-latest', 'mistral-medium'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-2508', 'mistral-medium'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-2508', 'mistral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-3b-2410', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1758788154, owned_by='mistralai', name='ministral-3b-2410', description='Official ministral-3b-2410 Mistral AI model', max_context_length=32768, aliases=['ministral-3b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='ministral-3b-latest', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1758788154, owned_by='mistralai', name='ministral-3b-2410', description='Official ministral-3b-2410 Mistral AI model', max_context_length=32768, aliases=['ministral-3b-2410'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='ministral-8b-2410', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='ministral-8b-2410', description='Powerful edge model with extremely high performance/price ratio.', max_context_length=131072, aliases=['ministral-8b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-8b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='ministral-8b-2410', description='Powerful edge model with extremely high performance/price ratio.', max_context_length=131072, aliases=['ministral-8b-2410'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-7b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['mistral-tiny', 'mistral-tiny-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mistral-nemo', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo-2407', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-nemo-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-2407'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mixtral-8x7b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mixtral-8x7b', description='Our first sparse mixture-of-experts released December 2023.', max_context_length=32768, aliases=['mistral-small', 'mistral-small-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mixtral-8x7b', description='Our first sparse mixture-of-experts released December 2023.', max_context_length=32768, aliases=['open-mixtral-8x7b', 'mistral-small-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mixtral-8x7b', description='Our first sparse mixture-of-experts released December 2023.', max_context_length=32768, aliases=['open-mixtral-8x7b', 'mistral-small'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mixtral-8x22b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mixtral-8x22b', description='Our best open source model to date released April 2024. ', max_context_length=65536, aliases=['open-mixtral-8x22b-2404'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mixtral-8x22b-2404', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='open-mixtral-8x22b', description='Our best open source model to date released April 2024. ', max_context_length=65536, aliases=['open-mixtral-8x22b'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-small-2409', description='Our latest enterprise-grade small model with the latest version v2 released September 2024. ', max_context_length=32768, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-large-2407', description='Our top-tier reasoning model for high-complexity tasks with the latest version v2 released July 2024.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-large-2411', description='Our top-tier reasoning model for high-complexity tasks with the lastest version released November 2024.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-latest', 'mistral-large-pixtral-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-2411', 'mistral-large-pixtral-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-pixtral-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-2411', 'pixtral-large-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-2501', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=262144, aliases=['codestral-2412', 'codestral-2411-rc5'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-2412', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=262144, aliases=['codestral-2501', 'codestral-2411-rc5'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-2411-rc5', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=262144, aliases=['codestral-2501', 'codestral-2412'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-2508', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-2508', description='Our cutting-edge language model for coding released August 2025.', max_context_length=256000, aliases=['codestral-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-2508', description='Our cutting-edge language model for coding released August 2025.', max_context_length=256000, aliases=['codestral-2508'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='devstral-small-2505', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='devstral-small-2505', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='devstral-small-2507', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=['devstral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='devstral-small-2507', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=['devstral-small-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-medium-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='devstral-medium-2507', description='Our medium code-agentic model.', max_context_length=131072, aliases=['devstral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='devstral-medium-2507', description='Our medium code-agentic model.', max_context_length=131072, aliases=['devstral-medium-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='pixtral-12b-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b', 'pixtral-12b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2501', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-small-2501', description='Our latest enterprise-grade small model with the latest version released January 2025. ', max_context_length=32768, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2503', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-small-2503', description='Our latest enterprise-grade small model with the latest version released March 2025.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-small-2506', description='Our latest enterprise-grade small model with the latest version released June 2025.', max_context_length=131072, aliases=['mistral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-small-2506', description='Our latest enterprise-grade small model with the latest version released June 2025.', max_context_length=131072, aliases=['mistral-small-2506'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-saba-2502', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-saba-2502', description='Official mistral-saba-2502 Mistral AI model', max_context_length=32768, aliases=['mistral-saba-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-saba-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-saba-2502', description='Official mistral-saba-2502 Mistral AI model', max_context_length=32768, aliases=['mistral-saba-2502'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='magistral-medium-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-medium-2506', description='Our frontier-class reasoning model released June 2025.', max_context_length=40960, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-medium-2507', description='Our frontier-class reasoning model released July 2025.', max_context_length=40960, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-small-2506', description='Our efficient reasoning model released June 2025.', max_context_length=40000, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-small-2507', description='Our efficient reasoning model released July 2025.', max_context_length=40960, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-2509', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-medium-2509', description='Our frontier-class reasoning model release candidate September 2025.', max_context_length=131072, aliases=['magistral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-medium-2509', description='Our frontier-class reasoning model release candidate September 2025.', max_context_length=131072, aliases=['magistral-medium-2509'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-2509', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-small-2509', description='Our efficient reasoning model released September 2025.', max_context_length=131072, aliases=['magistral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='magistral-small-2509', description='Our efficient reasoning model released September 2025.', max_context_length=131072, aliases=['magistral-small-2509'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='voxtral-mini-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-mini-2507', description='A mini audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-mini-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-mini-2507', description='A mini audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-mini-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-small-2507', description='A small audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-small-2507', description='A small audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-small-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='mistral-embed-2312', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-embed-2312', description='Official mistral-embed-2312 Mistral AI model', max_context_length=8192, aliases=['mistral-embed'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-embed', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-embed-2312', description='Official mistral-embed-2312 Mistral AI model', max_context_length=8192, aliases=['mistral-embed-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='codestral-embed', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-embed', description='Official codestral-embed Mistral AI model', max_context_length=8192, aliases=['codestral-embed-2505'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='codestral-embed-2505', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='codestral-embed', description='Official codestral-embed Mistral AI model', max_context_length=8192, aliases=['codestral-embed'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-2411', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1758788154, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=8192, aliases=['mistral-moderation-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-latest', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1758788154, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=8192, aliases=['mistral-moderation-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-ocr-2503', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-ocr-2503', description='Official mistral-ocr-2503 Mistral AI model', max_context_length=16384, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='mistral-ocr-2505', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-ocr-2505', description='Official mistral-ocr-2505 Mistral AI model', max_context_length=16384, aliases=['mistral-ocr-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='mistral-ocr-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1758788154, owned_by='mistralai', name='mistral-ocr-2505', description='Official mistral-ocr-2505 Mistral AI model', max_context_length=16384, aliases=['mistral-ocr-2505'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-transcribe-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-2507', 'voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-transcribe-2507', 'voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1758788154, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-transcribe-2507', 'voxtral-mini-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base')]\n"
     ]
    }
   ],
   "source": [
    "print(client.models.list())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
