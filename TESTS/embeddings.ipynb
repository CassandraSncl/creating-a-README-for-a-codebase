{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5276e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "from mistralai import Mistral\n",
    "import faiss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc30834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Charger la clé depuis le fichier .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "client = Mistral(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ec1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Lire fichiers .py et .ipynb\n",
    "def read_code(folder, extensions={\".py\", \".ipynb\"}, show_structure=False):\n",
    "    \"\"\"\n",
    "    Parcourt un dossier récursivement et extrait le contenu des fichiers .py et .ipynb.\n",
    "    \n",
    "    Args:\n",
    "        folder (str): chemin du dossier\n",
    "        extensions (set): extensions de fichiers à inclure\n",
    "        show_structure (bool): si True, affiche l’arborescence du dossier\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: liste de tuples (chemin_relatif, code_source)\n",
    "    \"\"\"\n",
    "    code_files = []\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(folder):\n",
    "        for f in filenames:\n",
    "            ext = os.path.splitext(f)[1].lower()\n",
    "            if ext in extensions:\n",
    "                full_path = os.path.join(dirpath, f)\n",
    "                rel_path = os.path.relpath(full_path, folder)\n",
    "                try:\n",
    "                    if ext == \".ipynb\":\n",
    "                        with open(full_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                            nb = json.load(file)\n",
    "                            code = \"\"\n",
    "                            for cell in nb.get(\"cells\", []):\n",
    "                                if cell.get(\"cell_type\") == \"code\":\n",
    "                                    code += \"\".join(cell.get(\"source\", [])) + \"\\n\"\n",
    "                            code_files.append((rel_path, code))\n",
    "                    else:\n",
    "                        with open(full_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                            code = file.read()\n",
    "                            code_files.append((rel_path, code))\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lecture {rel_path} : {e}\")\n",
    "\n",
    "    if show_structure:\n",
    "        print(\"Contenu du dossier :\")\n",
    "        for path, _ in code_files:\n",
    "            print(\" -\", path)\n",
    "\n",
    "    return code_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3a00f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Découper par fonction\n",
    "def split_functions(code):\n",
    "    pattern = r\"(def [\\w_]+\\s*\\(.*?\\):(?:\\n(?:\\s+.+))*)\"\n",
    "    funcs = re.findall(pattern, code, re.DOTALL)\n",
    "    return funcs if funcs else [code]\n",
    "\n",
    "# 3. Créer embeddings\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "\n",
    "def create_embeddings(chunks, batch_size=16, max_retries=5):\n",
    "    \"\"\"\n",
    "    Crée des embeddings pour une liste de textes (chunks) en batch\n",
    "    et gère les erreurs 429 avec retry exponentiel.\n",
    "    \n",
    "    Args:\n",
    "        chunks (list of str): textes à encoder\n",
    "        batch_size (int): nombre de chunks à envoyer par requête\n",
    "        max_retries (int): nombre de tentatives en cas d'erreur 429\n",
    "    Returns:\n",
    "        embeddings (list of np.array): embeddings de chaque chunk\n",
    "    \"\"\"\n",
    "    embeddings = []\n",
    "\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i+batch_size]\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                resp = client.embeddings.create(\n",
    "                    model=\"codestral-embed\",\n",
    "                    inputs=batch\n",
    "                )\n",
    "                # Ajouter chaque embedding du batch\n",
    "                for emb in resp.data:\n",
    "                    embeddings.append(np.array(emb.embedding, dtype=np.float32))\n",
    "                break  # sortir de la boucle retry si OK\n",
    "            except Exception as e:\n",
    "                # Vérifie si c'est une erreur 429\n",
    "                if \"429\" in str(e):\n",
    "                    wait = 2 ** attempt + random.random()\n",
    "                    print(f\"Erreur 429, tentative {attempt+1}/{max_retries}. Attente {wait:.2f}s\")\n",
    "                    time.sleep(wait)\n",
    "                else:\n",
    "                    raise e  # autre erreur → remonter\n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "224e0f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contenu du dossier :\n",
      " - code3.py\n",
      " - DOSSIER 2/code2.py\n",
      " - DOSSIER 2/code4.ipynb\n",
      " - DOSSIER 1/code5.ipynb\n",
      " - DOSSIER 1/code1.py\n",
      "Réponse du LLM :\n",
      " # README.md\n",
      "\n",
      "## Description\n",
      "\n",
      "Ce dépôt contient un ensemble de fonctions utilitaires pour la manipulation de fichiers, de calculs mathématiques et de création de DataFrames. Le code est organisé en plusieurs fonctions indépendantes pour faciliter son utilisation dans divers projets.\n",
      "\n",
      "## Fonctions disponibles\n",
      "\n",
      "### Fonctions de manipulation de fichiers\n",
      "- `list_files(folder)` : Liste les fichiers dans un dossier spécifié.\n",
      "- `create_folder(folder)` : Crée un dossier s'il n'existe pas déjà.\n",
      "- `create_file(path, content)` : Crée un fichier avec le contenu spécifié.\n",
      "- `read_file(path)` : Lit le contenu d'un fichier.\n",
      "- `count_lines(file_path)` : Compte le nombre de lignes dans un fichier.\n",
      "\n",
      "### Fonctions mathématiques\n",
      "- `add(a, b)` : Additionne deux nombres.\n",
      "- `multiply(a, b)` : Multiplie deux nombres.\n",
      "- `divide(a, b)` : Divise deux nombres (avec gestion de la division par zéro).\n",
      "- `subtract(a, b)` : Soustrait deux nombres.\n",
      "- `factorial(n)` : Calcule la factorielle d'un nombre.\n",
      "\n",
      "### Fonction de création de DataFrame\n",
      "- `create_dataframe(list_letters, list_numbers=None)` : Crée un DataFrame pandas avec des lettres et éventuellement des nombres.\n",
      "\n",
      "## Prérequis\n",
      "\n",
      "Pour utiliser ce code, vous aurez besoin des bibliothèques suivantes :\n",
      "- `os` (inclus dans Python standard)\n",
      "- `pandas` (pour la fonction `create_dataframe`)\n",
      "\n",
      "## Installation\n",
      "\n",
      "1. Clonez ce dépôt :\n",
      "   ```bash\n",
      "   git clone https://github.com/votre-utilisateur/votre-depot.git\n",
      "   ```\n",
      "\n",
      "2. Installez les dépendances nécessaires :\n",
      "   ```bash\n",
      "   pip install pandas\n",
      "   ```\n",
      "\n",
      "## Utilisation\n",
      "\n",
      "Importez les fonctions nécessaires dans votre script Python :\n",
      "\n",
      "```python\n",
      "from votre_module import list_files, create_file, add, create_dataframe\n",
      "\n",
      "# Exemple d'utilisation\n",
      "files = list_files(\"mon_dossier\")\n",
      "create_file(\"mon_fichier.txt\", \"Contenu du fichier\")\n",
      "resultat = add(5, 3)\n",
      "df = create_dataframe(['A', 'B', 'C'], [1, 2, 3])\n",
      "```\n",
      "\n",
      "## Exemples\n",
      "\n",
      "1. **Manipulation de fichiers** :\n",
      "   ```python\n",
      "   create_folder(\"nouveau_dossier\")\n",
      "   create_file(\"nouveau_dossier/fichier.txt\", \"Hello World!\")\n",
      "   contenu = read_file(\"nouveau_dossier/fichier.txt\")\n",
      "   print(contenu)\n",
      "   ```\n",
      "\n",
      "2. **Calculs mathématiques** :\n",
      "   ```python\n",
      "   print(add(10, 5))        # 15\n",
      "   print(multiply(4, 3))   # 12\n",
      "   print(divide(10, 2\n"
     ]
    }
   ],
   "source": [
    "# 4. Lire + chunker + embeddings\n",
    "folder = \"/Users/aya31/Desktop/M2 MIASHS/Calcul Paralle/creating-a-README-for-a-codebase/TESTS/TEST2\"\n",
    "all_code = read_code(folder, show_structure=True)\n",
    "\n",
    "all_chunks = []\n",
    "chunk_to_path = []\n",
    "\n",
    "for path, code in all_code:\n",
    "    chunks = split_functions(code)\n",
    "    all_chunks.extend(chunks)\n",
    "    chunk_to_path.extend([path] * len(chunks))  # pour traçabilité\n",
    "\n",
    "\n",
    "# 4 bis. Créer les embeddings à partir des chunks\n",
    "embeddings = create_embeddings(all_chunks, batch_size=8)\n",
    "\n",
    "\n",
    "# 5. Stocker dans FAISS\n",
    "dim = len(embeddings[0])\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "index.add(np.array(embeddings))\n",
    "\n",
    "# 6. Fonction pour poser une question au LLM avec RAG\n",
    "def ask_question(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Pose une question sur le code en utilisant RAG avec Mistral plus léger.\n",
    "    \"\"\"\n",
    "    # 1. Créer l'embedding de la question\n",
    "    query_emb = client.embeddings.create(\n",
    "        model=\"codestral-embed\",  # embeddings restent les mêmes\n",
    "        inputs=[query]\n",
    "    )\n",
    "    q_vec = np.array(query_emb.data[0].embedding, dtype=np.float32).reshape(1, -1)\n",
    "\n",
    "    # 2. Chercher les chunks les plus proches dans FAISS\n",
    "    D, I = index.search(q_vec, k=top_k)\n",
    "    context = \"\\n\\n\".join([all_chunks[i] for i in I[0]])\n",
    "\n",
    "    # 3. Préparer le prompt pour le LLM\n",
    "    prompt = (\n",
    "        \"Voici le code extrait :\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"Question : {query}\\n\"\n",
    "        \"Réponds de manière claire et précise, explique le fonctionnement du code si nécessaire. Donne les bibliothèques utilisées et à installer. \"\n",
    "    )\n",
    "\n",
    "    # 4. Appeler le LLM Mistral plus léger\n",
    "    response = client.chat.complete(\n",
    "        model=\"codestral-2508\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.2,\n",
    "        max_tokens=600\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "# 7. Exemple\n",
    "question = \"Redige un readme (gitub) pour ce dossier\"\n",
    "answer = ask_question(question)\n",
    "print(\"Réponse du LLM :\\n\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cf59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object='list' data=[BaseModelCard(id='mistral-medium-2505', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-medium-2505', description='Our frontier-class multimodal model released May 2025.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-large-latest', description='Official mistral-large-latest Mistral AI model', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium-2508', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-latest', 'mistral-medium'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-2508', 'mistral-medium'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-medium', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-medium-2508', description='Update on Mistral Medium 3 with improved capabilities.', max_context_length=131072, aliases=['mistral-medium-2508', 'mistral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-3b-2410', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='ministral-3b-2410', description=\"World's best edge model.\", max_context_length=131072, aliases=['ministral-3b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-3b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='ministral-3b-2410', description=\"World's best edge model.\", max_context_length=131072, aliases=['ministral-3b-2410'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-8b-2410', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='ministral-8b-2410', description='Powerful edge model with extremely high performance/price ratio.', max_context_length=131072, aliases=['ministral-8b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='ministral-8b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='ministral-8b-2410', description='Powerful edge model with extremely high performance/price ratio.', max_context_length=131072, aliases=['ministral-8b-2410'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-7b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['mistral-tiny', 'mistral-tiny-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-tiny-2312', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-7b', description='Our first dense model released September 2023.', max_context_length=32768, aliases=['open-mistral-7b', 'mistral-tiny'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='open-mistral-nemo', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo-2407', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='open-mistral-nemo-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'mistral-tiny-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-2407', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-tiny-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='open-mistral-nemo', description='Our best multilingual open source model released July 2024.', max_context_length=131072, aliases=['open-mistral-nemo', 'open-mistral-nemo-2407', 'mistral-tiny-2407'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-large-2411', description='Our top-tier reasoning model for high-complexity tasks with the lastest version released November 2024.', max_context_length=131072, aliases=[], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-latest', 'mistral-large-pixtral-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='pixtral-large-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-2411', 'mistral-large-pixtral-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-large-pixtral-2411', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-large-2411', description='Official pixtral-large-2411 Mistral AI model', max_context_length=131072, aliases=['pixtral-large-2411', 'pixtral-large-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-2508', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-2508', description='Our cutting-edge language model for coding released August 2025.', max_context_length=256000, aliases=['codestral-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-2508', description='Our cutting-edge language model for coding released August 2025.', max_context_length=256000, aliases=['codestral-2508'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='devstral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-small-2507', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=['devstral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-small-2507', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=['devstral-small-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-medium-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-medium-2507', description='Our medium code-agentic model.', max_context_length=131072, aliases=['devstral-medium-latest', 'mistral-vibe-cli-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='devstral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-medium-2507', description='Our medium code-agentic model.', max_context_length=131072, aliases=['devstral-medium-2507', 'mistral-vibe-cli-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='mistral-vibe-cli-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-medium-2507', description='Our medium code-agentic model.', max_context_length=131072, aliases=['devstral-medium-2507', 'devstral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='pixtral-12b-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b', 'pixtral-12b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='pixtral-12b-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='pixtral-12b-2409', description='A 12B model with image understanding capabilities in addition to text.', max_context_length=131072, aliases=['pixtral-12b-2409', 'pixtral-12b'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-small-2506', description='Our latest enterprise-grade small model with the latest version released June 2025.', max_context_length=131072, aliases=['mistral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-small-2506', description='Our latest enterprise-grade small model with the latest version released June 2025.', max_context_length=131072, aliases=['mistral-small-2506'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='magistral-medium-2509', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-medium-2509', description='Our frontier-class reasoning model release candidate September 2025.', max_context_length=131072, aliases=['magistral-medium-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-medium-2509', description='Our frontier-class reasoning model release candidate September 2025.', max_context_length=131072, aliases=['magistral-medium-2509'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-2509', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-small-2509', description='Our efficient reasoning model released September 2025.', max_context_length=131072, aliases=['magistral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-small-2509', description='Our efficient reasoning model released September 2025.', max_context_length=131072, aliases=['magistral-small-2509'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='voxtral-mini-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-mini-2507', description='A mini audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-mini-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-mini-2507', description='A mini audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-mini-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-small-2507', description='A small audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-small-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='voxtral-small-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-small-2507', description='A small audio understanding model released in July 2025', max_context_length=32768, aliases=['voxtral-small-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.2, TYPE='base'), BaseModelCard(id='devstral-small-2505', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='devstral-small-2505', description='Our small open-source code-agentic model.', max_context_length=131072, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='devstral-small-latest', default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='magistral-small-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-small-2506', description='Our efficient reasoning model released June 2025.', max_context_length=40000, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='magistral-small-latest', default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-2506', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-medium-2506', description='Our frontier-class reasoning model released June 2025.', max_context_length=40960, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='magistral-medium-latest', default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-small-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-small-2507', description='Our efficient reasoning model released July 2025.', max_context_length=40960, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='magistral-small-latest', default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='magistral-medium-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='magistral-medium-2507', description='Our frontier-class reasoning model released July 2025.', max_context_length=40960, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='magistral-medium-latest', default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='mistral-small-2409', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-small-2409', description='Our latest enterprise-grade small model with the latest version v2 released September 2024. ', max_context_length=32768, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='mistral-small-latest', default_model_temperature=0.7, TYPE='base'), BaseModelCard(id='codestral-2501', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=256000, aliases=['codestral-2412', 'codestral-2411-rc5'], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='codestral-latest', default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-2412', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=256000, aliases=['codestral-2501', 'codestral-2411-rc5'], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='codestral-latest', default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='codestral-2411-rc5', capabilities=ModelCapabilities(completion_chat=True, completion_fim=True, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-2501', description='Our cutting-edge language model for coding released December 2024.', max_context_length=256000, aliases=['codestral-2501', 'codestral-2412'], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='codestral-latest', default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2503', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-small-2503', description='Our latest enterprise-grade small model with the latest version released March 2025.', max_context_length=131072, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='mistral-small-latest', default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-small-2501', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=True, fine_tuning=True, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-small-2501', description='Our latest enterprise-grade small model with the latest version released January 2025. ', max_context_length=32768, aliases=[], deprecation=datetime.datetime(2025, 11, 30, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='mistral-small-latest', default_model_temperature=0.3, TYPE='base'), BaseModelCard(id='mistral-embed-2312', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-embed-2312', description='Official mistral-embed-2312 Mistral AI model', max_context_length=8192, aliases=['mistral-embed'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-embed', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-embed-2312', description='Official mistral-embed-2312 Mistral AI model', max_context_length=8192, aliases=['mistral-embed-2312'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='codestral-embed', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-embed', description='Official codestral-embed Mistral AI model', max_context_length=8192, aliases=['codestral-embed-2505'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='codestral-embed-2505', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='codestral-embed', description='Official codestral-embed Mistral AI model', max_context_length=8192, aliases=['codestral-embed'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-2411', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1763399316, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=8192, aliases=['mistral-moderation-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-moderation-latest', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=True), object='model', created=1763399316, owned_by='mistralai', name='mistral-moderation-2411', description='Official mistral-moderation-2411 Mistral AI model', max_context_length=8192, aliases=['mistral-moderation-2411'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=None, TYPE='base'), BaseModelCard(id='mistral-ocr-2505', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-ocr-2505', description='Official mistral-ocr-2505 Mistral AI model', max_context_length=16384, aliases=['mistral-ocr-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='mistral-ocr-latest', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-ocr-2505', description='Official mistral-ocr-2505 Mistral AI model', max_context_length=16384, aliases=['mistral-ocr-2505'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='mistral-ocr-2503', capabilities=ModelCapabilities(completion_chat=False, completion_fim=False, function_calling=True, fine_tuning=False, vision=True, classification=False), object='model', created=1763399316, owned_by='mistralai', name='mistral-ocr-2503', description='Official mistral-ocr-2503 Mistral AI model', max_context_length=16384, aliases=[], deprecation=datetime.datetime(2026, 3, 31, 12, 0, tzinfo=TzInfo(UTC)), deprecation_replacement_model='mistral-ocr-latest', default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-transcribe-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-2507', 'voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-2507', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-transcribe-2507', 'voxtral-mini-latest'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base'), BaseModelCard(id='voxtral-mini-latest', capabilities=ModelCapabilities(completion_chat=True, completion_fim=False, function_calling=False, fine_tuning=False, vision=False, classification=False), object='model', created=1763399316, owned_by='mistralai', name='voxtral-mini-transcribe-2507', description='A mini transcription model released in July 2025', max_context_length=16384, aliases=['voxtral-mini-transcribe-2507', 'voxtral-mini-2507'], deprecation=None, deprecation_replacement_model=None, default_model_temperature=0.0, TYPE='base')]\n"
     ]
    }
   ],
   "source": [
    "print(client.models.list())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mon_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
